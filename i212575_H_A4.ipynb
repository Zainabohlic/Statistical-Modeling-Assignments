{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e14882-2f10-4a89-9298-4db67c62127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05bd1f3-3497-40da-aa3a-2076e25c81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fish.csv\")\n",
    "x = data['Width']\n",
    "y = data['Height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "379e1ee2-ac02-46f2-b969-f1f9ab9d1a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/dice/lib/python3.8/site-packages/deprecat/classic.py:215: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  return wrapped_(*args_, **kwargs_)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [epsilon_linear, beta_linear, alpha_linear]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 00:02&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 10 seconds.\n",
      "/Applications/anaconda3/envs/dice/lib/python3.8/site-packages/deprecat/classic.py:215: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "  return wrapped_(*args_, **kwargs_)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [epsilon_poly, beta2_poly, beta1_poly, alpha_poly]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='12000' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [12000/12000 00:04&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 11 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "/Applications/anaconda3/envs/dice/lib/python3.8/site-packages/arviz/data/io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n",
      "Got error No model on context stack. trying to find log_likelihood in translation.\n",
      "/Applications/anaconda3/envs/dice/lib/python3.8/site-packages/arviz/data/io_pymc3_3x.py:98: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model  elpd_loo_waic  p_loo_waic  elpd_diff\n",
      "0        Linear    -380.677012    2.705710  -4.405435\n",
      "1  Polynomial^2    -376.271577    3.091168  -4.405435\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define the Linear Model using PyMC3\n",
    "with pm.Model() as linear_model:\n",
    "    alpha_linear = pm.Normal('alpha_linear', mu=0, sd=10)\n",
    "    beta_linear = pm.Normal('beta_linear', mu=0, sd=10)\n",
    "    epsilon_linear = pm.HalfNormal('epsilon_linear', sd=1)\n",
    "    mu_linear = alpha_linear + beta_linear * x\n",
    "    likelihood_linear = pm.Normal('likelihood_linear', mu=mu_linear, sd=epsilon_linear, observed=y)\n",
    "\n",
    "# Step 3: Define the Polynomial^2 Model using PyMC3\n",
    "with pm.Model() as poly_model:\n",
    "    alpha_poly = pm.Normal('alpha_poly', mu=0, sd=10)\n",
    "    beta1_poly = pm.Normal('beta1_poly', mu=0, sd=10)\n",
    "    beta2_poly = pm.Normal('beta2_poly', mu=0, sd=10)\n",
    "    epsilon_poly = pm.HalfNormal('epsilon_poly', sd=1)\n",
    "    mu_poly = alpha_poly + beta1_poly * x + beta2_poly * x**2\n",
    "    likelihood_poly = pm.Normal('likelihood_poly', mu=mu_poly, sd=epsilon_poly, observed=y)\n",
    "\n",
    "# Step 4: Fit the models\n",
    "with linear_model:\n",
    "    linear_trace = pm.sample(2000, tune=1000)\n",
    "\n",
    "with poly_model:\n",
    "    poly_trace = pm.sample(2000, tune=1000)\n",
    "\n",
    "# Step 5: Calculate LOO or WAIC\n",
    "linear_waic = az.waic(linear_trace, linear_model)\n",
    "poly_waic = az.waic(poly_trace, poly_model)\n",
    "\n",
    "# Step 6: Extract relevant information\n",
    "elpd_loo_waic = [linear_waic.waic, poly_waic.waic]\n",
    "p_loo_waic = [linear_waic.p_waic, poly_waic.p_waic]\n",
    "elpd_diff = linear_waic.waic - poly_waic.waic\n",
    "\n",
    "# Step 7: Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Model': ['Linear', 'Polynomial^2'],\n",
    "    'elpd_loo_waic': elpd_loo_waic,\n",
    "    'p_loo_waic': p_loo_waic,\n",
    "    'elpd_diff': elpd_diff\n",
    "})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2be9782-8ee4-4f35-924d-cc044bb8d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1\n",
      "\n",
      "The elpd_loo_waic represents the estimated log pointwise predictive density under leave-one-out cross-validation.\n",
      "The higher the value, the better the model.\n",
      "\n",
      "Linear Model:\n",
      " - elpd_loo_waic: -380.606466\n",
      " - p_loo_waic: 2.667605\n",
      "\n",
      "Polynomial^2 Model:\n",
      " - elpd_loo_waic: -376.30875\n",
      " - p_loo_waic: 3.123392\n",
      "\n",
      "The p_loo_waic is the effective number of parameters.\n",
      "Lower values are generally better, as they suggest a more parsimonious model.\n",
      "\n",
      "In this case:\n",
      " - Linear model has a lower p_loo_waic value: 2.667605\n",
      " - Polynomial^2 model has a higher p_loo_waic value: 3.123392\n",
      "\n",
      "The elpd_diff is the difference in expected log predictive density between models.\n",
      "It gives an indication of how much better one model is than the other.\n",
      "\n",
      "In this case:\n",
      " - elpd_diff is negative, indicating that the Linear model is slightly worse than the Polynomial^2 model: -4.297716\n"
     ]
    }
   ],
   "source": [
    "# Provided information\n",
    "linear_elpd_loo_waic_modified = -380.606466\n",
    "linear_p_loo_waic_modified = 2.667605\n",
    "poly_elpd_loo_waic_modified = -376.308750\n",
    "poly_p_loo_waic_modified = 3.123392\n",
    "elpd_diff_modified = -4.297716\n",
    "\n",
    "print (\"\\nQuestion 1\\n\")\n",
    "\n",
    "# Print the summary\n",
    "print(\"The elpd_loo_waic represents the estimated log pointwise predictive density under leave-one-out cross-validation.\")\n",
    "print(\"The higher the value, the better the model.\")\n",
    "\n",
    "print(\"\\nLinear Model:\")\n",
    "print(f\" - elpd_loo_waic: {linear_elpd_loo_waic_modified}\")\n",
    "print(f\" - p_loo_waic: {linear_p_loo_waic_modified}\")\n",
    "\n",
    "print(\"\\nPolynomial^2 Model:\")\n",
    "print(f\" - elpd_loo_waic: {poly_elpd_loo_waic_modified}\")\n",
    "print(f\" - p_loo_waic: {poly_p_loo_waic_modified}\")\n",
    "\n",
    "print(\"\\nThe p_loo_waic is the effective number of parameters.\")\n",
    "print(\"Lower values are generally better, as they suggest a more parsimonious model.\")\n",
    "\n",
    "print(\"\\nIn this case:\")\n",
    "print(f\" - Linear model has a lower p_loo_waic value: {linear_p_loo_waic_modified}\")\n",
    "print(f\" - Polynomial^2 model has a higher p_loo_waic value: {poly_p_loo_waic_modified}\")\n",
    "\n",
    "print(\"\\nThe elpd_diff is the difference in expected log predictive density between models.\")\n",
    "print(\"It gives an indication of how much better one model is than the other.\")\n",
    "\n",
    "print(\"\\nIn this case:\")\n",
    "print(f\" - elpd_diff is negative, indicating that the Linear model is slightly worse than the Polynomial^2 model: {elpd_diff_modified}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75e3bd9-2488-4cac-8cd8-9cda0b086279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2\n",
      "\n",
      "Linear Model:\n",
      "\n",
      " - p_loo_waic: 2.667605\n",
      "\n",
      "Polynomial^2 Model:\n",
      "\n",
      " - p_loo_waic: 3.123392\n",
      "\n",
      "The p_loo_waic for the Polynomial^2 model is higher than that of the Linear model.\n",
      "Therefore, based on the table, the Polynomial^2 model is considered more complex.\n",
      "This is likely due to the additional parameters introduced by the quadratic term (beta2 * x^2),\n",
      "making the Polynomial^2 model more flexible and potentially able to capture more complex patterns in the data.\n",
      "\n",
      "It's important to note that the choice between a simpler and more complex model often involves a trade-off\n",
      "between model fit and model simplicity. In this case, the decision on which model to choose may depend on\n",
      "the specific goals of your analysis and your willingness to trade off complexity for predictive accuracy.\n"
     ]
    }
   ],
   "source": [
    "# Provided information\n",
    "linear_p_loo_waic_modified = 2.667605\n",
    "poly_p_loo_waic_modified = 3.123392\n",
    "\n",
    "print (\"\\nQuestion 2\\n\")\n",
    "\n",
    "# Print the summary\n",
    "print(\"Linear Model:\")\n",
    "print(f\"\\n - p_loo_waic: {linear_p_loo_waic_modified}\")\n",
    "\n",
    "print(\"\\nPolynomial^2 Model:\")\n",
    "print(f\"\\n - p_loo_waic: {poly_p_loo_waic_modified}\")\n",
    "\n",
    "print(\"\\nThe p_loo_waic for the Polynomial^2 model is higher than that of the Linear model.\")\n",
    "print(\"Therefore, based on the table, the Polynomial^2 model is considered more complex.\")\n",
    "print(\"This is likely due to the additional parameters introduced by the quadratic term (beta2 * x^2),\")\n",
    "print(\"making the Polynomial^2 model more flexible and potentially able to capture more complex patterns in the data.\")\n",
    "\n",
    "print(\"\\nIt's important to note that the choice between a simpler and more complex model often involves a trade-off\")\n",
    "print(\"between model fit and model simplicity. In this case, the decision on which model to choose may depend on\")\n",
    "print(\"the specific goals of your analysis and your willingness to trade off complexity for predictive accuracy.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
